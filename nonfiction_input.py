import streamlit as st
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from openai import OpenAI
import logging
from datetime import datetime
from PIL import Image
from general_text_input import TextToWebtoonConverter
from io import BytesIO
from image_gen import generate_image_from_text
from save_utils import save_session
from clip_analyzer import CLIPAnalyzer  # CLIP ë¶„ì„ê¸° ì¶”ê°€


@dataclass
class NonFictionConfig:
    style: str
    visualization_type: str
    aspect_ratio: str
    num_images: int
    emphasis: str = "clarity"

class NonFictionConverter:
    def __init__(self, openai_client: OpenAI):
        self.client = openai_client
        self.setup_logging()
        
        # ì‹œê°í™” íƒ€ì…ì„ ìŠ¤í† ë¦¬í…”ë§ ë°©ì‹ìœ¼ë¡œ ë³€ê²½
        self.visualization_types = {
           "ì„¤ëª…í•˜ê¸°": {
        "prompt": "simple minimalistic shapes, thin and sharp lines, clean composition, no text",
        "layout": "minimalistic single-concept layout",
        "elements": "sole object, no unnecessary shading or details",
        "style": "educational minimalistic style with thin lines"
    },
    "ë¹„êµí•˜ê¸°": {
        "prompt": "two-column comparison, thin outlines, minimalistic shapes, clean layout, no unnecessary details",
        "layout": "side-by-side layout, focus on clear differences",
        "elements": "precise shapes, no shading, no text",
        "style": "minimalistic cartoon style with fine lines"
    },
    "ê³¼ì • ë³´ì—¬ì£¼ê¸°": {
        "prompt": "step-by-step flow, clean lines, thin minimalistic shapes, cartoon-like simplicity without exaggeration",
        "layout": "horizontal or vertical progression with arrows",
        "elements": "single-colored shapes, no gradients, no text",
        "style": "thin line cartoon minimalistic style"
    },
    "ì›ë¦¬ ì„¤ëª…í•˜ê¸°": {
        "prompt": "cause-and-effect diagram with minimalistic shapes, thin lines, plain white background, no text",
        "layout": "input-output or cause-effect structure",
        "elements": "clear, distinct shapes, no complex details",
        "style": "scientific minimalistic style with cartoon simplicity"
    }
}

    @staticmethod
    def setup_logging():
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )

    def split_content_into_scenes(self, text: str, num_scenes: int) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„¤ëª… ê°€ëŠ¥í•œ ì¥ë©´ë“¤ë¡œ ë¶„í• """
        try:
            prompt = f"""ë‹¤ìŒ ë‚´ìš©ì„ {num_scenes}ê°œì˜ í•µì‹¬ ì¥ë©´ìœ¼ë¡œ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.
        ê° ì¥ë©´ì€ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

        ë¶„ì„ ê¸°ì¤€:
        1. ì¤‘ìš” ê°œë…ì´ë‚˜ í•µì‹¬ ì•„ì´ë””ì–´ ìœ„ì£¼ë¡œ ì„ íƒ
        2. ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ì‰¬ìš´ ë¶€ë¶„ ìš°ì„ 
        3. ë‚´ìš©ì˜ ë…¼ë¦¬ì  íë¦„ ìœ ì§€
        4. ë³µì¡í•œ ë‚´ìš©ì€ ë‹¨ìˆœí•œ ê´€ê³„ë¡œ ì¬êµ¬ì„±
        5. ì¶”ìƒì ì¸ ê°œë…ì€ êµ¬ì²´ì ì¸ ë¹„ìœ ë¡œ ë³€í™˜

        í˜„ì¬ í…ìŠ¤íŠ¸:
        {text}

        ê° ì¥ë©´ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:
        - ì‹œê°ì  ìš”ì†Œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
        - ê´€ê³„ì™€ êµ¬ì¡°ë¥¼ ëª…í™•í•˜ê²Œ í‘œí˜„
        - í•œ ì¥ë©´ë‹¹ 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ê¸°ìˆ """

            
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )

            scenes = response.choices[0].message.content.strip().split("\n\n")
            return [scene.strip() for scene in scenes if scene.strip()][:num_scenes]
        
        except Exception as e:
            logging.error(f"Scene splitting failed: {str(e)}")
            return [text]

    def create_scene_description(self, scene: str, config: NonFictionConfig) -> str:
        """ì¥ë©´ì„ ì›¹íˆ° ìŠ¤íƒ€ì¼ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
        try:
        # visualization_typeì´ ìœ íš¨í•œì§€ í™•ì¸
            if config.visualization_type not in self.visualization_types:
                logging.error(f"Invalid visualization type: {config.visualization_type}")
                # ê¸°ë³¸ê°’ "ì„¤ëª…í•˜ê¸°" ì‚¬ìš©
                vis_type = self.visualization_types["ì„¤ëª…í•˜ê¸°"]
            else:
                vis_type = self.visualization_types[config.visualization_type]
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            max_length = 200
            content = scene[:max_length] if len(scene) > max_length else scene
            
            prompt = f"""Create a clear, simple educational illustration:

Main concept: {content}

Style requirements:
- {vis_type['style']}
- Layout: {vis_type['layout']}
- Elements: {vis_type['elements']}
- Visual style: {vis_type['prompt']}
- Single focused concept per image
- Bold, clean lines like manhwa/manga style
- Soft, pleasant color palette (2-3 colors maximum)
- White or very light background

Must include:
- One clear focal point
- Simple visual metaphor
- Easy-to-understand layout
- Gentle, rounded edges
- Ample white space around main element

Must avoid:
- Multiple competing concepts
- Complex diagrams or flowcharts
- Technical symbols or formulas
- Connecting lines or arrows
- Text labels or numbers
- Cluttered compositions
- Multiple scenes in one image
"""

            return prompt

        except Exception as e:
            logging.error(f"Scene description creation failed: {str(e)}")
            raise

    def process_submission(self, text: str, config: NonFictionConfig):
        
        """ì›¹íˆ° ìŠ¤íƒ€ì¼ì˜ êµìœ¡ ì»¨í…ì¸  ìƒì„±"""
        try:
            progress_bar = st.progress(0)
            status = st.empty()

            # ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ë°ì´í„° ì´ˆê¸°í™”
            if 'generation_logs' not in st.session_state:
                st.session_state.generation_logs = []

            # ë¶„ì„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = datetime.now()

            # CLIP ë¶„ì„ê¸° ì •ë³´ í‘œì‹œ
            st.sidebar.markdown("### ğŸ” CLIP ë¶„ì„ê¸° ì •ë³´")
            st.sidebar.info(f"ë””ë°”ì´ìŠ¤: {self.clip_analyzer.device}")
            st.sidebar.info(f"ëª¨ë¸: openai/clip-vit-base-patch32")

            # 1. í…ìŠ¤íŠ¸ë¥¼ ì„¤ëª… ê°€ëŠ¥í•œ ì¥ë©´ë“¤ë¡œ ë¶„í• 
            status.info("ğŸ“ ë‚´ìš© ë¶„ì„ ì¤‘...")
            scenes = self.split_content_into_scenes(text, config.num_images)
            progress_bar.progress(0.2)

            # 2. ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
            generated_images = {}
            scene_descriptions = []

            # ìƒì„± ë©”íŠ¸ë¦­ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
            generation_metrics = {
                'total_time': 0,
                'avg_clip_score': 0,
                'scores': [],
                'generation_attempts': []
            }

            # 3. ê° ì¥ë©´ë³„ ì²˜ë¦¬
            for i, scene in enumerate(scenes):
                scene_start_time = datetime.now()
                status.info(f"ğŸ¨ {i+1}/{len(scenes)} ì¥ë©´ ìƒì„± ì¤‘...")
            
                # ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self.create_scene_description(scene, config)
                scene_descriptions.append(prompt)
            
                # ì´ë¯¸ì§€ ìƒì„±
                image_url, _, _ = generate_image_from_text(
                    prompt=prompt,
                    style="minimalistic",
                    aspect_ratio=config.aspect_ratio,
                    negative_prompt=(
                         "abstract art, messy layout, unclear connections, "
                            "photorealistic style, 3d rendering, "
                                "complex textures, dark colors, "
                                    "artistic interpretation, painterly style"
                    )
                    )
            
                if image_url:
                    generated_images[i] = image_url
                
                    # CLIP ê²€ì¦ ë° í’ˆì§ˆ ë¶„ì„
                    quality_check = self.clip_analyzer.validate_image(
                        image_url, 
                        prompt,
                        return_score=True
                    )

                    if i % 2 == 0:
                        cols = st.columns(min(2, config.num_images - i))
                
                    with cols[i % 2]:
                        # ì´ë¯¸ì§€ í‘œì‹œ
                        st.image(image_url, use_column_width=True)
                    
                        # ë¶„ì„ ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•œ expander ì¶”ê°€
                        with st.expander("ğŸ” CLIP ë¶„ì„ ê²°ê³¼", expanded=False):
                            col1, col2 = st.columns(2)
                            score = quality_check.get("similarity_score", 0.0)
                        
                            with col1:
                                st.metric("í’ˆì§ˆ ì ìˆ˜", f"{score:.2f}")
                            with col2:
                                if score >= 0.7:
                                    st.success("âœ“ ë†’ì€ í’ˆì§ˆ")
                                elif score >= 0.5:
                                    st.warning("â–³ ì¤‘ê°„ í’ˆì§ˆ")
                                else:
                                    st.error("âš  ë‚®ì€ í’ˆì§ˆ")
                        
                            # ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                            st.write("í”„ë¡¬í”„íŠ¸ ë§¤ì¹­:")
                            st.progress(score)
                        
                            # ìƒì„± ì‹œê°„ í‘œì‹œ
                            scene_time = (datetime.now() - scene_start_time).total_seconds()
                            st.info(f"â± ìƒì„± ì‹œê°„: {scene_time:.1f}ì´ˆ")
                    
                        # ì¥ë©´ ì„¤ëª… í‘œì‹œ
                        summary = self.summarize_scene(scene)
                        st.markdown(
                            f"<p style='text-align: center; font-size: 14px;'>{summary}</p>", 
                            unsafe_allow_html=True
                        )

                    # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    generation_metrics['scores'].append(score)
                    generation_metrics['generation_attempts'].append({
                        'scene_number': i + 1,
                        'clip_score': score,
                        'generation_time': scene_time
                    })
            
                progress_bar.progress((i + 1) / config.num_images)

            # ì „ì²´ ìƒì„± ì‹œê°„ ê³„ì‚°
            generation_metrics['total_time'] = (datetime.now() - start_time).total_seconds()
            generation_metrics['avg_clip_score'] = sum(generation_metrics['scores']) / len(generation_metrics['scores'])

            # ìƒì„± ë¡œê·¸ ì €ì¥
            st.session_state.generation_logs.append({
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'config': config.__dict__,
                'metrics': generation_metrics
            })

            # ìƒì„± ê²°ê³¼ ìš”ì•½ í‘œì‹œ
            st.sidebar.markdown("### ğŸ“Š ìƒì„± ê²°ê³¼ ìš”ì•½")
            st.sidebar.metric("í‰ê·  CLIP ì ìˆ˜", f"{generation_metrics['avg_clip_score']:.2f}")
            st.sidebar.metric("ì´ ìƒì„± ì‹œê°„", f"{generation_metrics['total_time']:.1f}ì´ˆ")

            # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
            st.session_state.generated_images = generated_images
            st.session_state.scene_descriptions = scene_descriptions

            status.success("âœ¨ ì›¹íˆ° ìƒì„± ì™„ë£Œ!")

         

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logging.error(f"Error in process_submission: {str(e)}")

    def summarize_scene(self, description: str) -> str:
        """ì¥ë©´ì˜ ë§¥ë½ê³¼ ì˜ë¯¸ë¥¼ ë‹´ì€ ì„¤ëª… ìƒì„±"""
        try:
            prompt = """ë‹¤ìŒ ì‹œê°ì  ì„¤ëª…ì„ ë³´ê³  ì¥ë©´ì˜ ë§¥ë½ê³¼ í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

        ìš”êµ¬ì‚¬í•­:
    1. ë‹¨ìˆœí•œ ì‹œê°ì  ë¬˜ì‚¬("~ì¥ë©´ì´ë‹¤")ëŠ” í”¼í•˜ê³ , ë§¥ë½ê³¼ ì˜ë¯¸ë¥¼ ë‹´ì•„ì£¼ì„¸ìš”
    2. ê°€ëŠ¥í•œ í˜„ì¬í˜•ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
    3. í•„ìš”ì‹œ ì¸ê³¼ê´€ê³„ë‚˜ ë³€í™”ë¥¼ í¬í•¨í•´ë„ ì¢‹ìŠµë‹ˆë‹¤
    4. ìµœëŒ€ 70ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

    ì˜ˆì‹œ:
    âŒ "ì›ê³¼ í™”ì‚´í‘œê°€ ì—°ê²°ëœ ì¥ë©´ì´ë‹¤"
    â­• "ë¬¼ì´ ìˆ˜ì¦ê¸°ë¡œ ë³€í•˜ë©° ìˆœí™˜í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤"

    âŒ "ë‘ ê°œì˜ ì‚¬ê°í˜•ì´ ë¹„êµëœ ì¥ë©´ì´ë‹¤"
    â­• "ê³ ì²´ì™€ ì•¡ì²´ ìƒíƒœì—ì„œ ë¶„ìì˜ ì›€ì§ì„ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤"

    âŒ "ì¸ë¬¼ì´ ìˆëŠ” ë°°ê²½ ì¥ë©´ì´ë‹¤"
    â­• "í™˜ê²½ì˜¤ì—¼ìœ¼ë¡œ ì¸í•´ ì§€êµ¬ì˜ ì˜¨ë„ê°€ ê³„ì† ìƒìŠ¹í•˜ê³  ìˆìŠµë‹ˆë‹¤"

    ì„¤ëª…í•  ë‚´ìš©:
    {description}"""

            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": description}
                ],
                temperature=0.7,
                max_tokens=200
            )
        
            summary = response.choices[0].message.content.strip()
            # ë§ˆì¹¨í‘œê°€ ì—†ë‹¤ë©´ ì¶”ê°€
            if not summary.endswith(('.', '!', '?')):
                summary += '.'
            return summary[:150]
    
        except Exception as e:
            logging.error(f"Scene summarization failed: {str(e)}")
            return description[:70]
                

    def render_ui(self):
       #UI ë‹¨ìˆœí™”
        st.title("êµìœ¡/ ê³¼í•™ í…ìŠ¤íŠ¸ ì‹œê°í™”í•˜ê¸°")
        with st.sidebar.expander("ğŸ“š ì‹œê°í™” ê°€ì´ë“œ", expanded=True):
            st.markdown("""
                        ### ğŸ¯ ì‹œê°í™” ë°©ì‹
        - **ì„¤ëª…í•˜ê¸°**: ê°œë…ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬
          - _ë‹¨ìˆœí•˜ê³  ì§ê´€ì ì¸ ë„ì‹í™”_
          - _í•µì‹¬ ìš”ì†Œ ê°•ì¡°_
        
        - **ë¹„êµí•˜ê¸°**: ì°¨ì´ì  ë˜ëŠ” íŠ¹ì§• ëŒ€ì¡°
          - _ë‚˜ë€í•œ êµ¬ì¡°ë¡œ í‘œí˜„_
          - _ë³€í™”ë‚˜ ì°¨ì´ ë¶€ê°_
        
        - **ê³¼ì • ë³´ì—¬ì£¼ê¸°**: ë‹¨ê³„ë³„ ë³€í™” ì„¤ëª…
          - _ìˆœì°¨ì  íë¦„ í‘œí˜„_
          - _ì¸ê³¼ê´€ê³„ ëª…í™•í™”_
        
        - **ì›ë¦¬ ì„¤ëª…í•˜ê¸°**: ì‘ë™ ë°©ì‹ ì‹œê°í™”
          - _êµ¬ì¡°ì™€ ê´€ê³„ í‘œí˜„_
          - _ë©”ì»¤ë‹ˆì¦˜ ë„ì‹í™”_
        
        ### ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¹„ìœ¨
        - **ì •ì‚¬ê°í˜• (1:1)**: ê· í˜•ì¡íŒ ë„ì‹
        - **ì™€ì´ë“œ (16:9)**: ê³¼ì •ì´ë‚˜ íë¦„ í‘œí˜„
        - **ì„¸ë¡œí˜• (9:16)**: ê³„ì¸µ êµ¬ì¡°ë‚˜ ìˆœì„œ í‘œí˜„
        
        ### ğŸ“Š ì´ë¯¸ì§€ ìˆ˜ëŸ‰
        - **1ì¥**: í•µì‹¬ ê°œë… ì§‘ì¤‘
        - **2ì¥**: ë¹„êµ ë˜ëŠ” ì „í›„ ê´€ê³„
        - **3ì¥**: ë‹¨ê³„ë³„ ì§„í–‰ ê³¼ì •
        - **4ì¥**: ìƒì„¸í•œ ë¶„ì„ì´ë‚˜ ì„¤ëª…
        """)
        
        st.info("""
        ğŸ’¡ **íš¨ê³¼ì ì¸ ì‹œê°í™” íŒ**
        - ë³µì¡í•œ ë‚´ìš©ì€ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ í‘œí˜„í•˜ì„¸ìš”
        - í•µì‹¬ ê°œë…ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ì„¸ìš”
        - ì§ê´€ì ì¸ ë„í˜•ê³¼ í™”ì‚´í‘œë¥¼ í™œìš©í•˜ì„¸ìš”
        - ê´€ë ¨ëœ ìš”ì†Œë“¤ì€ ê°™ì€ ìƒ‰ìƒìœ¼ë¡œ ë¬¶ì–´ì£¼ì„¸ìš”
        """)
                        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if 'generated_images' not in st.session_state:
            st.session_state.generated_images = {}
            st.session_state.current_config = None
            st.session_state.current_text = None
            st.session_state.scene_descriptions = []
         # ì…ë ¥ ë°©ì‹ ì„ íƒ
        input_method = st.radio(
            "ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”",
            ["ì§ì ‘ ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ"],
            horizontal=True
        )

        with st.form("nonfiction_input_form"):

            text_content = None
            if input_method == "ì§ì ‘ ì…ë ¥":
                text_content = st.text_area(
                    "ì„¤ëª…í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
                    placeholder="ì–´ë ¤ìš´ ë‚´ìš©ì„ ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”.",
                    height=200
             )
            else:
                uploaded_file=st.file_uploader(
                    "íŒŒì¼ ì—…ë¡œë“œ",
                type=['txt', 'pdf', 'docx', 'doc'],
                help="ì§€ì› í˜•ì‹: TXT, PDF, DOCX"
                )
                if uploaded_file:
                    text_content=TextToWebtoonConverter.read_file_content(uploaded_file)
                    if text_content:
                        st.success("íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ!")
                        with st.expander("íŒŒì¼ ë‚´ìš© í™•ì¸"):
                            st.text(text_content[:500] + "..." if len(text_content) > 500 else text_content)
            col1, col2 = st.columns(2)

            with col1:
                visualization_type = st.selectbox(
                "ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í• ê¹Œìš”?",
                list(self.visualization_types.keys()),  
                help="ì»¨í…ì¸ ì— ê°€ì¥ ì í•©í•œ ì„¤ëª… ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
                num_images = st.radio(
                "ëª‡ ì¥ì˜ ê·¸ë¦¼ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
                options=[1, 2, 3, 4],
                horizontal=True
            )

            with col2:
                aspect_ratio = st.selectbox(
                "ì´ë¯¸ì§€ ë¹„ìœ¨",
                ["ì •ì‚¬ê°í˜• (1:1)", "ì™€ì´ë“œ (16:9)", "ì„¸ë¡œí˜• (9:16)"]
                )

            submit = st.form_submit_button("âœ¨ ì›¹íˆ° ìƒì„± ì‹œì‘")

            if submit and text_content:
                ratio_map = {
                "ì •ì‚¬ê°í˜• (1:1)": "1:1",
                "ì™€ì´ë“œ (16:9)": "16:9",
                "ì„¸ë¡œí˜• (9:16)": "9:16"
            }
            
                config = NonFictionConfig(
                style="webtoon",  # ì›¹íˆ° ìŠ¤íƒ€ì¼ë¡œ ê³ ì •
                visualization_type=visualization_type,
                aspect_ratio=ratio_map.get(aspect_ratio, "1:1"),
                num_images=num_images,
                emphasis="clarity"
            )
                 # ì„¸ì…˜ ìƒíƒœì— í˜„ì¬ ì„¤ì • ì €ì¥
                st.session_state.current_config = config
                st.session_state.current_text = text_content
                self.process_submission(text_content, config)
            
            elif submit:
                st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    
    def create_scene_description(self, scene: str, config: NonFictionConfig) -> str:
      #ê° ì¥ë©´ì— ëŒ€í•œ ì‹œê°í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        try:
            vis_type = self.visualization_types[config.visualization_type]
            
        # ê¸°ë³¸ ìŠ¤íƒ€ì¼ê³¼ ì„ íƒëœ ì‹œê°í™” íƒ€ì… ê²°í•©
            prompt = f"""Create a simple and friendly cartoon visualization:

            Content to explain: {scene}

            Style:
            - Simple cartoon style like children's book illustrations
            - Clean and easy to understand
            - Use cute and friendly elements
            - Minimal details, maximum clarity

            Visual approach: {vis_type['prompt']}
            Layout: {vis_type['layout']}
            Main elements: {vis_type['elements']}

            Key requirements:
            - Keep it super simple and friendly
            - Use basic shapes and cute symbols
            - Make it instantly understandable
            - Avoid complex details
            - Use clear, cheerful colors
            - Make it engaging and fun

            Complexity: {config.complexity} (but keep it simple regardless)"""

            return prompt

        except Exception as e:
            logging.error(f"Scene description creation failed: {str(e)}")
            raise

    def _parse_analysis_response(self, response_text: str) -> Dict[str, float]:
    #"""ë¶„ì„ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì ìˆ˜ë¡œ ë³€í™˜"""
         try:
        # ê°„ë‹¨í•œ íŒŒì‹± ë¡œì§ êµ¬í˜„
            scores = {
            "process": 0.5,
            "concept": 0.5,
            "system": 0.5,
            "comparison": 0.5
        }
            return scores
         except Exception as e:
            logging.error(f"Analysis parsing failed: {str(e)}")
            return {"process": 0.5, "concept": 0.5, "system": 0.5, "comparison": 0.5}

    def process_submission(self, text: str, config: NonFictionConfig):
    #"""ì—¬ëŸ¬ ì¥ì˜ ì´ë¯¸ì§€ ìƒì„± ë° ì²˜ë¦¬"""
        try:
            progress_bar = st.progress(0)
            status = st.empty()

        # 1. í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¥ë©´ìœ¼ë¡œ ë¶„í• 
            status.info("ğŸ“ ë‚´ìš© ë¶„ì„ ì¤‘...")
            scenes = self.split_content_into_scenes(text, config.num_images)
            progress_bar.progress(0.2)

        # 2. ê° ì¥ë©´ë³„ ì²˜ë¦¬
            generated_images = []
            for i, scene in enumerate(scenes):
                status.info(f"ğŸ¨ {i+1}/{len(scenes)} ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            
            # ì¥ë©´ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self.create_scene_description(scene, config)
            
            # ì´ë¯¸ì§€ ìƒì„±
                image_url, revised_prompt, _ = generate_image_from_text(
                    prompt=prompt,
                    style="minimalist",  # í•­ìƒ ë¯¸ë‹ˆë©€ ìŠ¤íƒ€ì¼ ì‚¬ìš©
                    aspect_ratio=config.aspect_ratio,
                    negative_prompt=self.negative_elements
            )
            
                if image_url:
                # imported summarize_scene í•¨ìˆ˜ ì‚¬ìš©
                    summary = self.summarize_scene(scene)  # ìì²´ ë©”ì†Œë“œ ëŒ€ì‹  imported í•¨ìˆ˜ ì‚¬ìš©
                    generated_images.append({
                    "url": image_url,
                    "summary": summary,
                    "prompt": prompt,
                    "revised_prompt": revised_prompt
                })
            
                progress_bar.progress((i + 1) / len(scenes))

        # 3. ê²°ê³¼ í‘œì‹œ
            if generated_images:
                cols = st.columns(min(2, len(generated_images)))
                for i, img_data in enumerate(generated_images):
                    with cols[i % 2]:
                        st.image(img_data["url"], use_column_width=True)
                        st.markdown(f"<p style='text-align: center; font-size: 14px;'>{img_data['summary']}</p>", 
                              unsafe_allow_html=True)
                    
                        with st.expander(f"ì´ë¯¸ì§€ {i+1} ìƒì„¸ ì •ë³´"):
                            st.text(f"ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸:\n{img_data['prompt']}")
                            if img_data['revised_prompt']:
                                st.text(f"ìˆ˜ì •ëœ í”„ë¡¬í”„íŠ¸:\n{img_data['revised_prompt']}")

            progress_bar.progress(1.0)
            status.success("âœ¨ ì‹œê°í™”ëœ ì›¹íˆ° ìƒì„± ì™„ë£Œ!")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            logging.error(f"Error in process_submission: {str(e)}")
    def summarize_scene(self, description: str) -> str:
   # """ì¥ë©´ ì„¤ëª… ìš”ì•½"""
        try:
            prompt = """ë‹¤ìŒ ì‹œê°í™” ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:
        1. í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
        2. ê°ê´€ì ì¸ ì„¤ëª… ìœ„ì£¼
        3. í•µì‹¬ ìš”ì†Œë§Œ í¬í•¨
        4. ìµœëŒ€ 50ì ì´ë‚´
        
            ì„¤ëª…í•  ë‚´ìš©:"""
        
            response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": description}
            ],
            temperature=0.7,
            max_tokens=100
            )
        
            summary = response.choices[0].message.content.strip()
            return summary[:100]  # 50ìë¡œ ì œí•œ
        
        except Exception as e:
            logging.error(f"Scene summarization failed: {str(e)}")
            return description[:100]                
# The main function would be similar to your existing code
def main():
    st.set_page_config(
        page_title="Educational Webtoon Creator",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    try:
        client = OpenAI()
        converter = NonFictionConverter(client)
        converter.render_ui()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()